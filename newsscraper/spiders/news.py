import scrapyimport jsonimport osdirname = os.path.dirname(__file__)from ..items import NewsscraperItemfilename = os.path.join(dirname, 'test.json')with open(filename) as f:    d = json.load(f)    print(d['sites'])class NewsScrapper(scrapy.Spider):    name = 'newsScrap'    start_urls = d['sites']    def parse(self, response):        items = NewsscraperItem()        newsdiv = response.css('.article__media+ p')  # for getting title text        headline = response.css('.article__headline::text')[0].extract()        category = response.css('.t-p-color::text')[0].extract()        fullNews = response.css('p.article__content.article__content--intro::text')[0].extract()        gurl = response.url        print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')        print(response.url)        imageUrl = response.xpath('//*[@id="main-content"]/section/div/div[1]/article/div[2]/div[1]/figure[1]/div/a/img/@data-src')[0].extract()        items["headline"] = headline        items["category"] = category        items["fullnews"] = fullNews        items["imageUrl"] = imageUrl        items["url"] = gurl        yield items